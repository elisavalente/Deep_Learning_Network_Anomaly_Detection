{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute, preprocessing, metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_WebAttacks = pd.read_csv('CICIDS2017_Datasets\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', sep=';' , encoding='latin-1')\n",
    "dados_BruteForce = pd.read_csv('CICIDS2017_Datasets\\Tuesday-WorkingHours.pcap_ISCX.csv', sep=',')\n",
    "dados_Dos = pd.read_csv('CICIDS2017_Datasets\\Wednesday-workingHours.pcap_ISCX.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete rows with NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [dados_WebAttacks,dados_BruteForce,dados_Dos]:\n",
    "    i.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dados_WebAttacks,dados_BruteForce,dados_Dos:\n",
    "\n",
    "    df.drop(['Flow ID'],axis=1,inplace=True)\n",
    "    df.drop([' Timestamp'],axis=1,inplace=True)\n",
    "    df.drop([' Source IP'], axis=1,inplace=True)\n",
    "    df.drop([' Destination IP'], axis=1,inplace=True)\n",
    "    df[' Bwd Packet Length Std']=df[' Bwd Packet Length Std'].astype(np.float)\n",
    "    df['Flow Bytes/s']=df['Flow Bytes/s'].astype(np.float)\n",
    "    df[' Flow Packets/s']=df[' Flow Packets/s'].astype(np.float)\n",
    "    df[' Flow IAT Std']=df[' Flow IAT Std'].astype(np.float)\n",
    "    df['Fwd Packets/s']=df['Fwd Packets/s'].astype(np.float)\n",
    "    df[' Bwd Packets/s']=df[' Bwd Packets/s'].astype(np.float)\n",
    "    df[' Packet Length Mean']=df[' Packet Length Mean'].astype(np.float)\n",
    "    df[' Packet Length Std']=df[' Packet Length Std'].astype(np.float)\n",
    "    df[' Packet Length Variance']=df[' Packet Length Variance'].astype(np.float)\n",
    "    df[' Average Packet Size']=df[' Average Packet Size'].astype(np.float)\n",
    "    df[' Avg Fwd Segment Size']=df[' Avg Fwd Segment Size'].astype(np.float)\n",
    "    df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Column Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [dados_WebAttacks,dados_BruteForce,dados_Dos]:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    input_classes = i[' Label'].unique()\n",
    "    #print(input_classes)\n",
    "    label_encoder.fit(input_classes)\n",
    "    i[' Label'] = label_encoder.transform(i[' Label'])\n",
    "    #print(i[' Label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative values check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [dados_WebAttacks,dados_BruteForce,dados_Dos]:\n",
    "    columns = df.columns\n",
    "    #print('----------------------------')\n",
    "    for i in columns:\n",
    "        if (df[i] < 0).any():\n",
    "            number_of_negatives = np.sum((df[i] < 0).values.ravel())\n",
    "            #print(i + ' : '+ str(number_of_negatives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop single unique value features and the two features with high number of negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dados_WebAttacks,dados_BruteForce,dados_Dos:\n",
    "    i.drop([' Bwd PSH Flags'], axis=1,inplace=True)\n",
    "    i.drop([' Fwd URG Flags'], axis=1,inplace=True)\n",
    "    i.drop([' Bwd URG Flags'], axis=1,inplace=True)\n",
    "    i.drop([' CWE Flag Count'], axis=1,inplace=True)\n",
    "    i.drop(['Fwd Avg Bytes/Bulk'], axis=1,inplace=True)\n",
    "    i.drop([' Fwd Avg Packets/Bulk'], axis=1,inplace=True)\n",
    "    i.drop([' Fwd Avg Bulk Rate'], axis=1,inplace=True)\n",
    "    i.drop([' Bwd Avg Bytes/Bulk'], axis=1,inplace=True)\n",
    "    i.drop([' Bwd Avg Packets/Bulk'], axis=1,inplace=True)\n",
    "    i.drop(['Bwd Avg Bulk Rate'], axis=1,inplace=True)\n",
    "    i.drop(['Init_Win_bytes_forward'], axis=1,inplace=True) #muitos valores negativos\n",
    "    i.drop([' Init_Win_bytes_backward'], axis=1,inplace=True) #muitos valores negativos\n",
    "\n",
    "# Fix the webattack dataset  misspelled Fwd Header Length.1 feature   \n",
    "dados_WebAttacks.rename(columns={' Fwd Header Length_1':' Fwd Header Length.1'}, inplace=True)\n",
    "\n",
    "dados_WebAttacks = dados_WebAttacks.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_BruteForce = dados_BruteForce.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_Dos = dados_Dos.replace([np.inf, -np.inf], np.nan).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all rows with negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Convert negative values to NaN \n",
    "dados_WebAttacks_without_neg = dados_WebAttacks[dados_WebAttacks >= 0]\n",
    "dados_BruteForce_without_neg = dados_BruteForce[dados_BruteForce >= 0]\n",
    "dados_Dos_without_neg = dados_Dos[dados_Dos >= 0]\n",
    "\n",
    "############# Remove the rows with NaN \n",
    "dados_WebAttacks_without_neg = dados_WebAttacks_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_BruteForce_without_neg = dados_BruteForce_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_Dos_without_neg = dados_Dos_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the variables correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dados_Dos_without_neg.corr().abs()\n",
    "s = c.unstack()\n",
    "#print(s[' Label'])\n",
    "so = s.sort_values(kind=\"quicksort\")\n",
    "#print(so[-61:-1])\n",
    "\n",
    "filtered_correlation = {}\n",
    "for item in so.iteritems(): # retorna os valores das correlações entre 0.7 e 1 sem repetições\n",
    "    a = item[0][0]\n",
    "    b = item[0][1]\n",
    "    if (item[1] >= 0.7 and  item[1] < 1):\n",
    "        if not(b in filtered_correlation and a in filtered_correlation[b]):\n",
    "            if a not in filtered_correlation:\n",
    "                filtered_correlation[a] = {}\n",
    "            filtered_correlation[a][b]=item[1]\n",
    "\n",
    "for i in filtered_correlation: # print the values\n",
    "    for j in filtered_correlation[i]:\n",
    "        print(i + '\\t' + j + '\\t' + str(filtered_correlation[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the variables more than 70% correlated, remove one of variables of each correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dados_WebAttacks_without_neg,dados_BruteForce_without_neg,dados_Dos_without_neg:\n",
    "        i.drop([' Total Backward Packets'], axis=1,inplace=True)\n",
    "        i.drop([' Total Length of Bwd Packets'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd Packet Length Std'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd Packet Length Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Flow IAT Std'], axis=1,inplace=True)\n",
    "        i.drop(['Fwd IAT Total'], axis=1,inplace=True)\n",
    "        i.drop([' Packet Length Std'], axis=1,inplace=True)\n",
    "        i.drop([' Packet Length Variance'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd Header Length.1'], axis=1,inplace=True)\n",
    "        i.drop(['Subflow Fwd Packets'], axis=1,inplace=True)\n",
    "        i.drop([' Subflow Bwd Packets'], axis=1,inplace=True)\n",
    "        i.drop([' Subflow Bwd Bytes'], axis=1,inplace=True)\n",
    "        i.drop([' Active Max'], axis=1,inplace=True)\n",
    "        i.drop([' Active Min'], axis=1,inplace=True)\n",
    "        i.drop(['Idle Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Idle Min'], axis=1,inplace=True)\n",
    "        i.drop([' Idle Max'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd IAT Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd IAT Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Destination Port'], axis=1,inplace=True)\n",
    "        i.drop(['Bwd Packet Length Max'], axis=1,inplace=True)\n",
    "        i.drop([' Avg Fwd Segment Size'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd Packet Length Min'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd Header Length'], axis=1,inplace=True)\n",
    "        i.drop([' Max Packet Length'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd IAT Std'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd IAT Max'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd Packet Length Max'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd IAT Std'], axis=1,inplace=True)\n",
    "        i.drop([' Min Packet Length'], axis=1,inplace=True)\n",
    "        i.drop([' Flow Duration'], axis=1,inplace=True) \n",
    "        i.drop([' Flow IAT Min'], axis=1,inplace=True) \n",
    "        i.drop([' Flow IAT Max'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd IAT Min'], axis=1,inplace=True)\n",
    "        i.drop(['Fwd Packets/s'], axis=1,inplace=True)\n",
    "        i.drop([' ECE Flag Count'], axis=1,inplace=True)\n",
    "        i.drop([' Subflow Fwd Bytes'], axis=1,inplace=True)\n",
    "        i.drop([' SYN Flag Count'], axis=1,inplace=True)\n",
    "        i.drop([' Average Packet Size'], axis=1,inplace=True)\n",
    "        i.drop([' Packet Length Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Bwd Packet Length Mean'], axis=1,inplace=True)\n",
    "        i.drop([' Fwd Packet Length Std'], axis=1,inplace=True)\n",
    "\n",
    "dados_WebAttacks_without_neg.drop([' act_data_pkt_fwd'] , axis=1,inplace=True)\n",
    "dados_WebAttacks_without_neg.drop([' Total Fwd Packets'] , axis=1,inplace=True)\n",
    "dados_BruteForce_without_neg.drop([' Flow IAT Mean'] , axis=1,inplace=True)\n",
    "dados_BruteForce_without_neg.drop([' Total Fwd Packets'] , axis=1,inplace=True)\n",
    "dados_Dos_without_neg.drop([' Avg Bwd Segment Size'] , axis=1,inplace=True)\n",
    "dados_Dos_without_neg.drop([' Total Fwd Packets'] , axis=1,inplace=True)\n",
    "dados_Dos_without_neg.drop([' Fwd Header Length'] , axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [dados_WebAttacks_without_neg,dados_BruteForce_without_neg,dados_Dos_without_neg]:\n",
    "    columns = i.columns\n",
    "    for j in columns:\n",
    "        max=i[j].max()\n",
    "        if(max>10000):\n",
    "            i[j]=np.log(1 + i[j])\n",
    "\n",
    "dados_WebAttacks_without_neg = dados_WebAttacks_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_BruteForce_without_neg = dados_BruteForce_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "dados_Dos_without_neg = dados_Dos_without_neg.replace([np.inf, -np.inf], np.nan).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_WebAttacks_normalized = dados_WebAttacks_without_neg\n",
    "dados_BruteForce_normalized = dados_BruteForce_without_neg\n",
    "dados_Dos_normalized = dados_Dos_without_neg\n",
    "\n",
    "############## WebAttacks\n",
    "Web_columns = dados_WebAttacks_normalized.columns[:-1]\n",
    "dados_WebAttacks_normalized[Web_columns] = preprocessing.normalize(dados_WebAttacks_normalized[Web_columns], norm='max',axis=0)\n",
    "\n",
    "############## BruteForce\n",
    "BrutForce_columns = dados_BruteForce_normalized.columns[:-1]\n",
    "dados_BruteForce_normalized[BrutForce_columns] = preprocessing.normalize(dados_BruteForce_normalized[BrutForce_columns], norm='max',axis=0)\n",
    "\n",
    "############## Dos\n",
    "Dos_columns = dados_Dos_normalized.columns[:-1]\n",
    "dados_Dos_normalized[Dos_columns] = preprocessing.normalize(dados_Dos_normalized[Dos_columns], norm='max',axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_WebAttacks_normalized = dados_WebAttacks_normalized.drop_duplicates()\n",
    "dados_BruteForce_normalized = dados_BruteForce_normalized.drop_duplicates()\n",
    "dados_Dos_normalized = dados_Dos_normalized.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_WebAttacks_normalized = shuffle(dados_WebAttacks_normalized)\n",
    "dados_BruteForce_normalized = shuffle(dados_BruteForce_normalized)\n",
    "dados_Dos_normalized = shuffle(dados_Dos_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(dados_WebAttacks_normalized[' Label'])\n",
    "print(counter)\n",
    "counter = Counter(dados_BruteForce_normalized[' Label'])\n",
    "print(counter)\n",
    "counter = Counter(dados_Dos_normalized[' Label'])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web_Attack_Benign = dados_WebAttacks_normalized[' Label'] == 0\n",
    "Web_Attack_Brute_Force = dados_WebAttacks_normalized[' Label'] == 1\n",
    "Web_Attack_SQL_Injection = dados_WebAttacks_normalized[' Label'] == 2\n",
    "Web_Attack_XSS = dados_WebAttacks_normalized[' Label'] == 3\n",
    "#since Web_Attack_SQL_Injection won't be used, the value of the Web_Attack_XSS class should be changed for 2\n",
    "dados_WebAttacks_normalized.loc[Web_Attack_XSS,' Label']=2\n",
    "\n",
    "Brute_Force_Benign = dados_BruteForce_normalized[' Label'] == 0\n",
    "Brute_Force_FTP_Patator = dados_BruteForce_normalized[' Label'] == 1\n",
    "Brute_Force_SSH_Patator = dados_BruteForce_normalized[' Label'] == 2\n",
    "\n",
    "Dos_Benign = dados_Dos_normalized[' Label'] == 0\n",
    "Dos_GoldenEye = dados_Dos_normalized[' Label'] == 1\n",
    "DoS_Hulk = dados_Dos_normalized[' Label'] == 2\n",
    "DoS_Slowhttptest = dados_Dos_normalized[' Label'] == 3\n",
    "DoS_Slowlori = dados_Dos_normalized[' Label'] == 4\n",
    "Heartbleed = dados_Dos_normalized[' Label'] == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 66-33 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebAttack_Benign_train1, WebAttack_Benign_train2, WebAttack_Benign_test = np.array_split(dados_WebAttacks_normalized[Web_Attack_Benign], 3)\n",
    "WebAttack_Brute_Force_train1, WebAttack_Brute_Force_train2, WebAttack_Brute_Force_test = np.array_split(dados_WebAttacks_normalized[Web_Attack_Brute_Force], 3)\n",
    "Web_Attack_XSS_train1, Web_Attack_XSS_train2, Web_Attack_XSS_test = np.array_split(dados_WebAttacks_normalized[Web_Attack_XSS], 3)\n",
    "\n",
    "Brute_Force_Benign_train1, Brute_Force_Benign_train2, Brute_Force_Benign_test = np.array_split(dados_BruteForce_normalized[Brute_Force_Benign], 3)\n",
    "Brute_Force_FTP_Patator_train1, Brute_Force_FTP_Patator_train2, Brute_Force_FTP_Patator_test = np.array_split(dados_BruteForce_normalized[Brute_Force_FTP_Patator], 3)\n",
    "Brute_Force_SSH_Patator_train1, Brute_Force_SSH_Patator_train2, Brute_Force_SSH_Patator_test = np.array_split(dados_BruteForce_normalized[Brute_Force_SSH_Patator], 3)\n",
    "\n",
    "Dos_Benign_train1, Dos_Benign_train2, Dos_Benign_test = np.array_split(dados_Dos_normalized[Dos_Benign], 3)\n",
    "Dos_GoldenEye_train1, Dos_GoldenEye_train2, Dos_GoldenEye_test = np.array_split(dados_Dos_normalized[Dos_GoldenEye], 3)\n",
    "DoS_Hulk_train1, DoS_Hulk_train2, DoS_Hulk_test = np.array_split(dados_Dos_normalized[DoS_Hulk], 3)\n",
    "DoS_Slowhttptest_train1, DoS_Slowhttptest_train2, DoS_Slowhttptest_test = np.array_split(dados_Dos_normalized[DoS_Slowhttptest], 3)\n",
    "DoS_Slowlori_train1, DoS_Slowlori_train2, DoS_Slowlori_test = np.array_split(dados_Dos_normalized[DoS_Slowlori], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all train and test data and shuffle\n",
    "\n",
    "WebAttack_train = pd.concat([WebAttack_Benign_train1, WebAttack_Benign_train2, WebAttack_Brute_Force_train1, WebAttack_Brute_Force_train2, Web_Attack_XSS_train1, Web_Attack_XSS_train2])\n",
    "WebAttack_test = pd.concat([WebAttack_Benign_test, WebAttack_Brute_Force_test, Web_Attack_XSS_test])\n",
    "WebAttack_train = shuffle(WebAttack_train)\n",
    "WebAttack_test = shuffle(WebAttack_test)\n",
    "\n",
    "Brute_Force_train = pd.concat([Brute_Force_Benign_train1, Brute_Force_Benign_train2, Brute_Force_FTP_Patator_train1, Brute_Force_FTP_Patator_train2, Brute_Force_SSH_Patator_train1, Brute_Force_SSH_Patator_train2])\n",
    "Brute_Force_test = pd.concat([Brute_Force_Benign_test, Brute_Force_FTP_Patator_test, Brute_Force_SSH_Patator_test])\n",
    "Brute_Force_train = shuffle(Brute_Force_train)\n",
    "Brute_Force_test = shuffle(Brute_Force_test)\n",
    "\n",
    "Dos_train = pd.concat([Dos_Benign_train1, Dos_Benign_train2, Dos_GoldenEye_train1, Dos_GoldenEye_train2, DoS_Hulk_train1, DoS_Hulk_train2, DoS_Slowhttptest_train1, DoS_Slowhttptest_train2, DoS_Slowlori_train1, DoS_Slowlori_train2])\n",
    "Dos_test = pd.concat([Dos_Benign_test, Dos_GoldenEye_test, DoS_Hulk_test, DoS_Slowhttptest_test, DoS_Slowlori_test])\n",
    "Dos_train = shuffle(Dos_train)\n",
    "Dos_test = shuffle(Dos_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train and test data in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebAttack_train.to_csv(r'Train_test_data/WebAttack_train.csv', index = False)\n",
    "WebAttack_test.to_csv(r'Train_test_data/WebAttack_test.csv', index = False)\n",
    "\n",
    "Brute_Force_train.to_csv(r'Train_test_data/Brute_Force_train.csv', index = False)\n",
    "Brute_Force_test.to_csv(r'Train_test_data/Brute_Force_test.csv', index = False)\n",
    "\n",
    "Dos_train.to_csv(r'Train_test_data/Dos_train.csv', index = False)\n",
    "Dos_test.to_csv(r'Train_test_data/Dos_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for the GAN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_WebAttack_Brute_Force = pd.concat([WebAttack_Brute_Force_train1, WebAttack_Brute_Force_train2])\n",
    "GAN_WebAttack_Brute_Force = shuffle(GAN_WebAttack_Brute_Force)\n",
    "GAN_WebAttack_Brute_Force.to_csv(r'GAN_generation\\Web_Attack_Brute_Force_Data.csv', index = False)\n",
    "\n",
    "GAN_Web_Attack_XSS  = pd.concat([Web_Attack_XSS_train1, Web_Attack_XSS_train2])\n",
    "GAN_Web_Attack_XSS = shuffle(GAN_Web_Attack_XSS)\n",
    "GAN_Web_Attack_XSS.to_csv(r'GAN_generation\\Web_Attack_XSS_Data.csv', index = False)\n",
    "\n",
    "GAN_Brute_Force_FTP_Patator = pd.concat([Brute_Force_FTP_Patator_train1, Brute_Force_FTP_Patator_train2])\n",
    "GAN_Brute_Force_FTP_Patator = shuffle(GAN_Brute_Force_FTP_Patator)\n",
    "GAN_Brute_Force_FTP_Patator.to_csv(r'GAN_generation\\Brute_Force_FTP_Patator_Data.csv', index = False)\n",
    "\n",
    "GAN_Brute_Force_SSH_Patator = pd.concat([Brute_Force_SSH_Patator_train1, Brute_Force_SSH_Patator_train2])\n",
    "GAN_Brute_Force_SSH_Patator = shuffle(GAN_Brute_Force_SSH_Patator)\n",
    "GAN_Brute_Force_SSH_Patator.to_csv(r'GAN_generation\\Brute_Force_SSH_Patator_Data.csv', index = False)\n",
    "\n",
    "GAN_Dos_GoldenEye = pd.concat([Dos_GoldenEye_train1, Dos_GoldenEye_train2])\n",
    "GAN_Dos_GoldenEye = shuffle(GAN_Dos_GoldenEye)\n",
    "GAN_Dos_GoldenEye.to_csv(r'GAN_generation\\Dos_GoldenEye_Data.csv', index = False)\n",
    "\n",
    "GAN_DoS_Hulk = pd.concat([DoS_Hulk_train1, DoS_Hulk_train2])\n",
    "GAN_DoS_Hulk = shuffle(GAN_DoS_Hulk)\n",
    "GAN_DoS_Hulk.to_csv(r'GAN_generation\\DoS_Hulk_Data.csv', index = False)\n",
    "\n",
    "GAN_DoS_Slowhttptest = pd.concat([DoS_Slowhttptest_train1, DoS_Slowhttptest_train2])\n",
    "GAN_DoS_Slowhttptest = shuffle(GAN_DoS_Slowhttptest)\n",
    "GAN_DoS_Slowhttptest.to_csv(r'GAN_generation\\DoS_Slowhttptest_Data.csv', index = False)\n",
    "\n",
    "GAN_DoS_Slowlori = pd.concat([DoS_Slowlori_train1, DoS_Slowlori_train2])\n",
    "GAN_DoS_Slowlori = shuffle(GAN_DoS_Slowlori)\n",
    "GAN_DoS_Slowlori.to_csv(r'GAN_generation\\DoS_Slowlori_Data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the amount of data needed for GAN generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(WebAttack_train[' Label'])\n",
    "print(counter)\n",
    "\n",
    "counter = Counter(Brute_Force_train[' Label'])\n",
    "print(counter)\n",
    "\n",
    "counter = Counter(Dos_train[' Label'])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_WebAttack_Brute_Force.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
