{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDoS_train = pd.read_csv('Train_test_data/DDoS_train.csv', sep=',') \n",
    "DDoS_test = pd.read_csv('Train_test_data/DDoS_test.csv', sep=',') \n",
    "\n",
    "PortScan_train = pd.read_csv('Train_test_data/PortScan_train.csv', sep=',') \n",
    "PortScan_test = pd.read_csv('Train_test_data/PortScan_test.csv', sep=',') \n",
    "\n",
    "Bot_train = pd.read_csv('Train_test_data/Bot_train.csv', sep=',')\n",
    "Bot_test = pd.read_csv('Train_test_data/Bot_test.csv', sep=',') \n",
    "\n",
    "WebAttack_train = pd.read_csv('Train_test_data/WebAttack_train.csv', sep=',') \n",
    "WebAttack_test = pd.read_csv('Train_test_data/WebAttack_test.csv', sep=',') \n",
    "\n",
    "Brute_Force_train = pd.read_csv('Train_test_data/Brute_Force_train.csv', sep=',') \n",
    "Brute_Force_test = pd.read_csv('Train_test_data/Brute_Force_test.csv', sep=',') \n",
    "\n",
    "Dos_train = pd.read_csv('Train_test_data/Dos_train.csv', sep=',')\n",
    "Dos_test = pd.read_csv('Train_test_data/Dos_test.csv', sep=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GAN balanced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_Bot_train = pd.read_csv('GAN_generation\\GAN_Balanced_Data\\GAN_Bot_train.csv', sep=',')\n",
    "GAN_WebAttack_train = pd.read_csv('GAN_generation\\GAN_Balanced_Data\\GAN_WebAttack_train.csv', sep=',')\n",
    "GAN_Brute_Force_train = pd.read_csv('GAN_generation\\GAN_Balanced_Data\\GAN_Brute_Force_train.csv', sep=',')\n",
    "GAN_DoS_train = pd.read_csv('GAN_generation\\GAN_Balanced_Data\\GAN_DoS_train.csv', sep=',')\n",
    "\n",
    "WGAN_GP_Bot_train = pd.read_csv('GAN_generation\\WGAN_GP_Balanced_Data\\WGAN_GP_Bot_train.csv', sep=',')\n",
    "WGAN_GP_WebAttack_train = pd.read_csv('GAN_generation\\WGAN_GP_Balanced_Data\\WGAN_GP_WebAttack_train.csv', sep=',')\n",
    "WGAN_GP_Brute_Force_train = pd.read_csv('GAN_generation\\WGAN_GP_Balanced_Data\\WGAN_GP_Brute_Force_train.csv', sep=',')\n",
    "WGAN_GP_DoS_train = pd.read_csv('GAN_generation\\WGAN_GP_Balanced_Data\\WGAN_GP_DoS_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SMOTE balanced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE_Botnet_train = pd.read_csv('SMOTE_Balanced_Data\\Botnet_smote_train.csv', sep=',')\n",
    "SMOTE_WebAttack_train = pd.read_csv('SMOTE_Balanced_Data\\WebAttack_smote_train.csv', sep=',')\n",
    "SMOTE_Brute_Force_train = pd.read_csv('SMOTE_Balanced_Data\\Brute_Force_smote_train.csv', sep=',')\n",
    "SMOTE_DoS_train = pd.read_csv('SMOTE_Balanced_Data\\Dos_smote_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset X-Y train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DDoS_train = DDoS_train.values[:,:-1]\n",
    "X_DDoS_test = DDoS_test.values[:,:-1]\n",
    "\n",
    "Y_DDoS_train = DDoS_train.values[:,-1:]\n",
    "Y_DDoS_test = DDoS_test.values[:,-1:]\n",
    "\n",
    "\n",
    "X_PortScan_train = PortScan_train.values[:,:-1]\n",
    "X_PortScan_test = PortScan_test.values[:,:-1]\n",
    "\n",
    "Y_PortScan_train = PortScan_train.values[:,-1:]\n",
    "Y_PortScan_test = PortScan_test.values[:,-1:]\n",
    "\n",
    "\n",
    "X_Bot_train = Bot_train.values[:,:-1]\n",
    "X_Bot_test = Bot_test.values[:,:-1]\n",
    "\n",
    "Y_Bot_train = Bot_train.values[:,-1:]\n",
    "Y_Bot_test = Bot_test.values[:,-1:]\n",
    "\n",
    "\n",
    "#Multi-class label\n",
    "\n",
    "X_WebAttack_train = WebAttack_train.values[:,:-1]\n",
    "X_WebAttack_test = WebAttack_test.values[:,:-1]\n",
    "\n",
    "Y_WebAttack_train = WebAttack_train.values[:,-1:]\n",
    "Y_WebAttack_test = WebAttack_test.values[:,-1:]\n",
    "\n",
    "\n",
    "X_Brute_Force_train = Brute_Force_train.values[:,:-1]\n",
    "X_Brute_Force_test = Brute_Force_test.values[:,:-1]\n",
    "\n",
    "Y_Brute_Force_train = Brute_Force_train.values[:,-1:]\n",
    "Y_Brute_Force_test = Brute_Force_test.values[:,-1:]\n",
    "\n",
    "\n",
    "X_Dos_train = Dos_train.values[:,:-1]\n",
    "X_Dos_test = Dos_test.values[:,:-1]\n",
    "\n",
    "Y_Dos_train = Dos_train.values[:,-1:]\n",
    "Y_Dos_test = Dos_test.values[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated data X-Y train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN and WGAN-GP\n",
    "X_GAN_Bot_train = GAN_Bot_train.values[:,:-1]\n",
    "Y_GAN_Bot_train = GAN_Bot_train.values[:,-1:]\n",
    "\n",
    "X_WGAN_GP_Bot_train = WGAN_GP_Bot_train.values[:,:-1]\n",
    "Y_WGAN_GP_Bot_train = WGAN_GP_Bot_train.values[:,-1:]\n",
    "\n",
    "X_GAN_WebAttack_train = GAN_WebAttack_train.values[:,:-1]\n",
    "Y_GAN_WebAttack_train = GAN_WebAttack_train.values[:,-1:]\n",
    "\n",
    "X_WGAN_GP_WebAttack_train = WGAN_GP_WebAttack_train.values[:,:-1]\n",
    "Y_WGAN_GP_WebAttack_train = WGAN_GP_WebAttack_train.values[:,-1:]\n",
    "\n",
    "X_GAN_Brute_Force_train = GAN_Brute_Force_train.values[:,:-1]\n",
    "Y_GAN_Brute_Force_train = GAN_Brute_Force_train.values[:,-1:]\n",
    "\n",
    "X_WGAN_GP_Brute_Force_train = WGAN_GP_Brute_Force_train.values[:,:-1]\n",
    "Y_WGAN_GP_Brute_Force_train = WGAN_GP_Brute_Force_train.values[:,-1:]\n",
    "\n",
    "X_GAN_DoS_train = GAN_DoS_train.values[:,:-1]\n",
    "Y_GAN_DoS_train = GAN_DoS_train.values[:,-1:]\n",
    "\n",
    "X_WGAN_GP_DoS_train = WGAN_GP_DoS_train.values[:,:-1]\n",
    "Y_WGAN_GP_DoS_train = WGAN_GP_DoS_train.values[:,-1:]\n",
    "\n",
    "#SMOTE\n",
    "X_SMOTE_Botnet_train = SMOTE_Botnet_train.values[:,:-1]\n",
    "Y_SMOTE_Botnet_train = SMOTE_Botnet_train.values[:,-1:]\n",
    "\n",
    "X_SMOTE_WebAttack_train = SMOTE_WebAttack_train.values[:,:-1]\n",
    "Y_SMOTE_WebAttack_train = SMOTE_WebAttack_train.values[:,-1:]\n",
    "\n",
    "X_SMOTE_Brute_Force_train = SMOTE_Brute_Force_train.values[:,:-1]\n",
    "Y_SMOTE_Brute_Force_train = SMOTE_Brute_Force_train.values[:,-1:]\n",
    "\n",
    "X_SMOTE_DoS_train = SMOTE_DoS_train.values[:,:-1]\n",
    "Y_SMOTE_DoS_train = SMOTE_DoS_train.values[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the dataset for the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_WebAttack_train\n",
    "X_test = X_WebAttack_test\n",
    "\n",
    "Y_train = Y_WebAttack_train\n",
    "Y_test = Y_WebAttack_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (22,) but got array with shape (24,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4bddc08f5e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# compile the keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#binary_crossentropy# fit the keras model on the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    139\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (22,) but got array with shape (24,)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=22, activation='softmax')) #22 DDoS, #23 bot, 21 Portscan\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) #sigmoid\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #binary_crossentropy# fit the keras model on the dataset\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Prediction for binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = model.predict(X_test, verbose=0) #X_test\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict_classes(X_test, verbose=0) #X_test\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "print(classification_report(Y_test, yhat_classes, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN model for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "72987/72987 [==============================] - 2s 24us/step - loss: 0.3158 - acc: 0.9717\n",
      "Epoch 2/10\n",
      "72987/72987 [==============================] - 1s 19us/step - loss: 0.0854 - acc: 0.9852\n",
      "Epoch 3/10\n",
      "72987/72987 [==============================] - 1s 19us/step - loss: 0.0829 - acc: 0.9852\n",
      "Epoch 4/10\n",
      "72987/72987 [==============================] - 1s 19us/step - loss: 0.0647 - acc: 0.9852\n",
      "Epoch 5/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0430 - acc: 0.9852\n",
      "Epoch 6/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0376 - acc: 0.9851\n",
      "Epoch 7/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0343 - acc: 0.9881\n",
      "Epoch 8/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0316 - acc: 0.9906\n",
      "Epoch 9/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0274 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "72987/72987 [==============================] - 1s 17us/step - loss: 0.0231 - acc: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8ab57ccf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=24, activation='softmax')) #DoS = 23, webAttack e bruteForce 24\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation=\"softmax\")) # WebAttacks = 3 BruteForce = 3 Dos = 5\n",
    "# compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Prediction for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72985/72985 [==============================] - 2s 26us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.99757   1.00000   0.99878     71906\n",
      "         1.0    0.66814   0.80212   0.72903       753\n",
      "         2.0    0.00000   0.00000   0.00000       326\n",
      "\n",
      "    accuracy                        0.99349     72985\n",
      "   macro avg    0.55524   0.60071   0.57594     72985\n",
      "weighted avg    0.98972   0.99349   0.99154     72985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisa Valente\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "#y_pred\n",
    "y_pred_bool = np.argmax(y_pred.tolist(), axis=1)\n",
    "#y_pred_bool\n",
    "print(classification_report(Y_test, y_pred_bool, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "clf=tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.99954   0.99971   0.99962     71906\n",
      "         1.0    0.88066   0.85259   0.86640       753\n",
      "         2.0    0.68047   0.70552   0.69277       326\n",
      "\n",
      "    accuracy                        0.99688     72985\n",
      "   macro avg    0.85356   0.85261   0.85293     72985\n",
      "weighted avg    0.99689   0.99688   0.99688     72985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = clf.predict(X_test)\n",
    "print(classification_report(Y_test, yhat_probs, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
